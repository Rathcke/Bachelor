\section{Methods} \label{sec:methods}

\input{methods_distance.tex}
\input{methods_k-dist.tex}
\input{methods_clustering.tex}

\subsection{Naive, greedy clustering algorithm}

A very simple, naive, greedy clustering algorithm, \textsc{Naive-Clust}, has
been implemented and will be described briefly in this section.

Given a list of sequences and an initially empty list of centroids, the
algorithm works by iterating through the sequences and for every sequence, it
iterates through the list of centroids until a match is found or until the end
of the list. If a match is found, the sequences is added to the cluster
represented by the matching centroid, and otherwise the sequences becomes a new
centroid and is appended to the end of the list of centroids.

% TODO: complexity of algorithm
% This running time of this algorithm depends on the number of clusters in the
% output and therefore it might be around $O(c^2)$, where $c$ denoted the
% number of sequences, in the worst case where the number of clusters is equal
% to the number of sequences.  %O(k*(k-1)/2)

% TODO: refer to algorithm and implementation

This approach is not very useful in practice since it is very computationally
expensive in the worst case. The running time of the algorithm is very dependent
on the ordering of the sequences since the centroids will be in the same order
as in the list of sequences (i.e. the list of centroids is a subsequence of the
list of sequences) and if the first number of sequences happens to be good
centroids, which will match a lot of sequences, the algorithm will perform good
since the search for a centroid will end very early. However, if the first
sequences happen to be very dissimilar from the rest of the data, then these
will become centroids and will be compared against on every iteration even
though they might potentially never match anything.

Thus, there is a motivation to try and create more structure in the collection
of centroids, improve the search for a centroid to compare with the query
sequence or improving the ordering of the centroids.

% The problem with this approach is that it is potentially very computationally
% expensive to possible traverse the entire list of centroids for each
% iteration

% TODO: maybe mention the reason for introducing max_rejects and clustering
% algorithm based on greediness


\subsection{\textsc{Simple-Clust} algorithm}

Another clustering algorithm, named \textsc{Simple-Clust}, was developed and
implemented, and will be described in this section. \textsc{Simple-Clust}
tries to address some of the problems with the \textsc{Naive-Clust} algorithm
by imposing more structure on the collection of centroids and by giving up
after some fixed number of comparisons of a given query sequence.

\textsc{Simple-Clust} works by iterating sequentially through the sequences to
be clustered; the $max\_reject$ most frequent $k$-mers for the query sequence
are calculated and for each of these most frequent $k$-mers, a centroid which
has that $k$-mer as the most frequently occurring one (if one such centroid
exists) is compared with the query sequence to check if their similarity is
above the given threshold. The query sequence is assigned to the cluster for
the first centroid that matches the query sequence; if no such centroid is
found, out of the maximum possible $max\_reject$ number of tries, the query
sequence becomes a centroid for a new cluster and is added to the collection of
centroids along with the information about the most frequently occurring
$k$-mer in the sequence. Pseudocode for the algorithm is attached in appendix
\ref{app:simple-clust}.

This algorithm did not perform as well as hoped, in particular for larger $k$
the number of different possible $k$-mers increases exponentially and for e.g.
$k = 6$ and a four letter alphabet, there are $4^6 = 4096$ different $k$-mers
and therefore the lookup in line \ref{alg:line:simple_clust_lookup} of the
algorithm will often be unsuccessful. Additionally, the most frequently
occurring $k$-mer did not appear to be a sufficiently good characteristic for
choosing a centroid that is likely to match, as it is seen from the evaluation
in section \ref{sec:results}. To clarify, the correspondence between the most
frequently occurring $k$-mer of two sequences and the similarity of the
sequences, is evidently not very strong.
% TODO: Maybe move to results?


\subsection{\textsc{K-Clust} algorithm}
\label{sec:k-clust_algorithm}

This section describes another clustering algorithm that was developed and
implemented, named \textsc{K-Clust}, which looks at the set of $k$-mers
occurring in the query and target sequences and bases the decision of whether
to try comparing or not, on the cardinality of the intersection between these
sets. This way, the search for a likely match is not just determined by the
single most frequently occurring $k$-mer, as with \textsc{Simple-Clust}, but
rather all the occurring $k$-mers, regardless of their count. Additionally, the
centroids are stored in a doubly linked list and whenever a centroid matches a
sequence, that centroid is moved to the front of the list. This makes the
algorithm less sensitive to the ordering of the input sequences. The choice of
the centroids will still be made greedily though, in lack of well-performing
alternatives, but the algorithm should nonetheless be less prone to bad
performance caused by an unlucky ordering of the input sequences. Algorithm
\ref{alg:k-clust} shows pseudocode for the \textsc{K-Clust} algorithm.

The choice of whether to compare a query sequence with a centroid is decided
using the formula
\begin{equation}
  \abs{K(s) \cap K(c)} \geq \abs{K(c)} \cdot id \;
\end{equation}
where $s$ is the query sequence, $c$ is the centroid sequence and $id$ is the
threshold similarity. $K(x)$ denotes the number of $k$-mers in a sequence $x$.
In the \texttt{klust} program this value is hard coded to $k=6$ for performance
reasons.

The idea of moving a matching centroid to the front of the list is, among other
things, inspired by the observation that the results from \texttt{USEARCH} and
\texttt{VSEARCH} often contain a large number of very small clusters and even
singleton clusters, i.e. clusters consisting of just a single sequence.

\begin{algorithm}[H]
  \caption{\textsc{K-Clust}}
  \label{alg:k-clust}
  \begin{algorithmic}[1]
    \Require{$S$ is an array of [DR]NA sequences, $k \in \mathbb{Z}^+$,
            $max\_rejects \in \mathbb{Z}^+$ and $id \in [0,1]$}
    \Statex
    \Function{K-Clust}{$S, k, max\_rejects, id$}
      \State $centroids \gets [~]$ \Comment{initialize empty list of centroids}
      \ForAll{$s \in S$}
        \State $match \gets false$
        \State $rejects \gets 0$
        \State $close\_match \gets \mathtt{NULL}$

        \ForAll{$c \in centroids$}
          \If{$rejects$ \texttt{==} $max\_rejects$}
            \State $break$
          \EndIf

          \State
          \LineComment{$K(x)$: set of $k$-mers in $x$}
          \If{$|K(s) \cap K(c)| \geq |K(c)| \cdot id$}
            \If{\Call{\textsc{K-Dist}}{s, c, k} $ \geq id$}
              \State Add $s$ to cluster represented by $c$.
              \State Move $c$ to the front of $centroids$.
              \State $match \gets true$
              \State $break$
            \EndIf
            \State
            \If{\Call{has\_link}{c} \texttt{AND}
                  \Call{\textsc{K-Dist}}{s, c.link, k} $ \geq id$}
              \State Add $s$ to cluster represented by $c.link$.
              \State Move $c.link$ to the front of $centroids$.
              \State $match \gets true$
              \State $break$
            \EndIf
            \State $rejects \gets rejects + 1$
            \State $close\_match \gets c$
          \EndIf
        \EndFor
        \State
        \If{$\mathtt{NOT}\ match$}  \Comment{add new centroid to list}
          \If{$close\_match$ \texttt{!= NULL}}
            \State $s.link \gets close\_match$
          \EndIf
          \State Prepend $s$ to $centroids$.
        \EndIf
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{algorithm}

An illustration of the method is seen in Figure \ref{fig:k-clust}.

\begin{figure}[h!]
  \def\svgwidth{\columnwidth}
  \import{graphics/}{Prioritized_Intersect_Clust.pdf_tex}
  \caption{Illustration of \textsc{K-Clust}. The centroid labeled
    $3$ is pushed to the front of list because it was the latest match to a
    sequence. The centroids labeled $4$ and $5$ has a link to the centroids $0$
    and $1$ respectively because they have been close to matching them.}
  \label{fig:k-clust}
\end{figure}


\subsubsection{Time complexity analysis}

The \textsc{K-Clust} algorithm iterates over the array of sequences $S$, that
is $|S|$ iterations, and for each of these iterations, the algorithms iterates
over the list of centroids.

In the worst case, the $centroids$ list will grow with one element in each
iteration of the outer loop, because in the worst case, every sequence will
become a centroid of its own. Thus, the number of iterations in the innner loop
will be the sequence
\[
  1 + 2 + 3 + \ldots + |S| \,,
\]
that is, the $|S|$'th triangular number, which can be expresses as
\begin{equation}
  \frac{\abs{S}\left(\abs{S}+1\right)}{2} \,. \label{eq:triangular_number}
\end{equation}

The inner loop contains a constant amount of work and at most two calls to
\textsc{K-Dist}, which will also be treates as contant time in this context,
since the running time of the clustering algorithm will be expressed in the
number of sequences, rather than the lengths of the sequences. The $K(s) \cap
K(c)$ calculation of the intersection between the two sets of $k$-mers in
sequences $s$ and $c$, respectively, will also be treated as constant since it
also depends on the lengths of $s$ and $c$ and not on the number of sequences
to be clustered.

Thus, the \textsc{K-Clust} algorithm iterates over the contant amount of work
in the inner loop the number of times expressed in (\ref{eq:triangular_number})
and so the running time is quadratic in the number of sequences, i.e.:
\begin{equation}
  \mathcal{O}\left(\abs{S}^2\right)
\end{equation}

This is, however, just the worst case running time and on average the running
time will be much better since every sequence will rarely become a centroid of
its own.

% TODO: (maybe) analyze space complexity
