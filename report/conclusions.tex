\section{Project summary}

\subsection{Conclusions}
\label{sec:conclusions}

The implementation of the distance metric, the Manhattan distance using the
algorithm \textsc{K-Dist} shows excellent results in terms of speed. The
additional calculations caused by using windows does not add noticeable much
to the overall performance of the clustering program. It does, however,
provide more sensible results.
%TODO: resultater af manhattan med vindue vs uden.

At this point in the project, we have described and implemented a reasonably
fast distance metric, which might be able to compete with other existing
solutions, e.g. \texttt{UCLUST}, depending on the clustering algorithm used
with the distance metric. There is still room for improvement, however, for
instance we plan to implement storage of $k$-mer frequency vectors together
with the centroids such that these can be reused in subsequent similarity
calculations.

Additionally, there can be made more checks for the possibility of stopping a
comparison early, if it is already known that it will fail.

While the distance metric implementation can be improved we also need to keep
it sensitive. Changing the distance metrics to improve speed could mean a
drawback for its sensibility. We also plan to investigate alternative methods
to locate centroid candidates as the current implementation does not provide
good results.

\subsection{Future work}
\label{sec:future_work}
While the implementation has sped up the clustering and makes good clustering results, it does lack some key features due to time constraints.
The most important feature is the search for good centroid matches. 

%TODO: Conclusions

%TODO: Future work: Sensitive distance metric and quicker centroid locate (using the links)
